{
 "metadata": {
  "name": "",
  "signature": "sha256:47671662479b40cb1f3dc18754f4a2ef2bc69e30bbdafcfe7478fe465d50aa3e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Segmentation 101 (Image-based)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import os\n",
      "import functools\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import pandas as pd\n",
      "rng = np.random.seed(100)\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn import metrics\n",
      "\n",
      "from skimage import io, transform, exposure, filters, color\n",
      "\n",
      "from networks import get_net \n",
      " \n",
      "config = tf.ConfigProto()\n",
      "config.gpu_options.allow_growth = True\n",
      "tf.keras.backend.set_session(tf.Session(config=config))  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def misc_seg_metrics(pred, ann):    \n",
      "    \"\"\" Compute the spec, sens, acc  between two ndarrays.\n",
      "    \"\"\"\n",
      "    acc = [((pred==j)*(ann==j)).sum(dtype='float')/(ann==j).sum() for j in np.unique(ann)] \n",
      "    acc.append((pred==ann).sum()/float(ann.size))  \n",
      "    return acc \n",
      "    \n",
      "def misc_jaccard_index(pred, ann):\n",
      "    intersection = pred*ann\n",
      "    union = np.maximum(pred, ann)\n",
      "    return np.sum(intersection.astype(float))/np.sum(union)\n",
      "\n",
      "def misc_metrics(gt, pr, ma=None, thrs= 0.5):\n",
      "    assert(gt.size == pr.size)\n",
      "    if ma is None:\n",
      "        ma = np.ones(gt.shape, dtype=bool)\n",
      "    ma = np.ravel(ma).astype(bool)\n",
      "    gt = np.ravel(gt)\n",
      "    pr = np.ravel(pr)  \n",
      "    gt = gt[ma] \n",
      "    pr = pr[ma] \n",
      "    auc = metrics.roc_auc_score(gt, pr)  \n",
      "    p = (pr>=thrs).astype(int)\n",
      "    mets = misc_seg_metrics(p, gt)\n",
      "    f1 = metrics.f1_score(gt, p)\n",
      "    jac = misc_jaccard_index(p, gt) \n",
      "    return [auc, mets[0], mets[1], mets[2], f1, jac]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Path processing and train-val splitting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_df(fpath, data_dir):\n",
      "    df_train = pd.read_csv(fpath)\n",
      "    x_paths = df_train['im_name'].map(lambda s: os.path.join(data_dir,s))\n",
      "    y_paths = df_train['gt_name'].map(lambda s: os.path.join(data_dir,s))\n",
      "    return x_paths, y_paths\n",
      "\n",
      "### Training-Validation splits\n",
      "def trainval_splits(ftrain, data_dir, validation_split=0.2, random_state=rng):\n",
      "    x_train_paths, y_train_paths = read_df(ftrain, data_dir) \n",
      "    return train_test_split(x_train_paths, y_train_paths, \n",
      "                            test_size=validation_split,\n",
      "                            random_state=random_state)\n",
      "\n",
      "def _process_pathnames(fname, lname, resize=None):  \n",
      "    img = io.imread(fname)\n",
      "    gt = io.imread(lname)\n",
      "    if gt.ndim < 3:\n",
      "        gt  = np.expand_dims(gt, -1)\n",
      "    gt = gt[...,:1]\n",
      "    gt = (gt > 0).astype(int) # binarize the ground-truth\n",
      "    if resize is not None:\n",
      "        img = transform.resize(img, resize)\n",
      "        gt = transform.resize(gt, resize)\n",
      "        gt = gt >= filters.threshold_otsu(gt)\n",
      "    return img, gt "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data augmentation routines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Data augmentation routines\n",
      "def shift_img(img, gt, width_shift_range, height_shift_range, rotate_range): \n",
      "    if width_shift_range  or height_shift_range:\n",
      "        if width_shift_range:\n",
      "            width_shift_range = np.random.uniform(-width_shift_range * img.shape[1],\n",
      "                                                   width_shift_range * img.shape[1])\n",
      "        if height_shift_range:\n",
      "            height_shift_range = np.random.uniform(-height_shift_range * img.shape[0],\n",
      "                                                   height_shift_range * img.shape[0]) \n",
      "        tr = transform.AffineTransform(translation=(width_shift_range, height_shift_range )) \n",
      "        img = transform.warp(img, tr, preserve_range=True)\n",
      "        gt   = transform.warp(gt, tr, preserve_range=True)\n",
      "        \n",
      "    if rotate_range :\n",
      "        if isinstance(rotate_range, np.ScalarType):\n",
      "            degre = np.random.uniform(-rotate_range,rotate_range)\n",
      "        else:\n",
      "            degre = np.random.uniform(rotate_range[0], rotate_range[1])\n",
      "        img = transform.rotate(img, degre, preserve_range=True)\n",
      "        gt  = transform.rotate(gt, degre, preserve_range=True)\n",
      "        \n",
      "    return img, gt\n",
      "\n",
      "def flip_img(img, gt, horizontal_flip, vertical_flip):\n",
      "    if horizontal_flip:\n",
      "        flip_prob = np.random.uniform(0.0, 1.0)\n",
      "        img, gt = (img, gt) if flip_prob >= 0.5 else (np.flip(img, 1), np.flip(gt, 1))\n",
      "    if vertical_flip:\n",
      "        flip_prob = np.random.uniform(0.0, 1.0)\n",
      "        img, gt = (img, gt) if flip_prob >= 0.5 else (np.flip(img, 0), np.flip(gt, 0))\n",
      "    return img, gt\n",
      "\n",
      "def _process_img(img, gt, gamma=0,\n",
      "                clahe=False, gray=False, xyz=False, hed=False,\n",
      "                horizontal_flip=False, width_shift_range=0,\n",
      "                height_shift_range=0, vertical_flip=0, rotate_range=0):\n",
      "    img = exposure.rescale_intensity(img.astype(float), out_range=(0,1))\n",
      "    if gray:\n",
      "        img = color.rgb2gray(img)\n",
      "    if xyz:\n",
      "        img = color.rgb2xyz(img)\n",
      "    if hed:\n",
      "        img = color.rgb2hed(img)\n",
      "    img = exposure.rescale_intensity(img, out_range=(0,1))\n",
      "    if clahe:\n",
      "        img = exposure.equalize_adapthist(img)\n",
      "    if gamma:\n",
      "        img = exposure.adjust_gamma(img, gamma)\n",
      "        img = exposure.rescale_intensity(img, out_range=(0,1))\n",
      "    if img.ndim == 2:\n",
      "        img = np.expand_dims(img, -1) \n",
      "\n",
      "    img, gt = flip_img(img, gt, horizontal_flip, vertical_flip)    \n",
      "    img, gt = shift_img(img, gt, width_shift_range, height_shift_range, rotate_range) \n",
      "         \n",
      "    return img, gt\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data generator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _generator(im_paths, gt_paths, \n",
      "              reader_fn=functools.partial(_process_pathnames),\n",
      "              preproc_fn=functools.partial(_process_img),\n",
      "              batch_size=1, \n",
      "              MAX_IM_QUEUE=20):  \n",
      "    batch_x = []\n",
      "    batch_y = []\n",
      "    im_stack = dict() \n",
      "    while True:  \n",
      "        for im_path, gt_path in zip(im_paths, gt_paths) :   \n",
      "            hash_im = hash(im_path)\n",
      "            if not im_stack.has_key(hash_im):\n",
      "                img, gt = reader_fn(im_path, gt_path) \n",
      "                if len(im_stack.keys()) > MAX_IM_QUEUE:\n",
      "                    im_stack.popitem()\n",
      "                im_stack[hash_im] = (img, gt)\n",
      "            else:\n",
      "                img, gt = im_stack[hash_im] \n",
      "\n",
      "            pr_im, pr_gt  = preproc_fn(img, gt)   \n",
      "\n",
      "            if len(batch_x) < batch_size:\n",
      "                batch_x.append(pr_im)\n",
      "                batch_y.append(pr_gt)\n",
      "            else:\n",
      "                ret = (np.array(batch_x), np.array(batch_y))\n",
      "                batch_x, batch_y = [pr_im], [pr_gt]\n",
      "                yield ret \n",
      "\n",
      "\n",
      "def get_gen(x_train_paths, y_train_paths, batch_size=1,\n",
      "            width_shift_range=0, height_shift_range=0, \n",
      "            horizontal_flip=False,vertical_flip=False,\n",
      "            rotate_range=0, resize=None,\n",
      "            gamma=0, clahe=False, gray=False, xyz=False, hed=False,\n",
      "            MAX_IM_QUEUE=100):\n",
      " \n",
      "    prepro_cfg = dict(gamma=gamma, clahe=clahe,\n",
      "                    gray=gray, xyz=xyz, hed=hed, horizontal_flip=horizontal_flip,\n",
      "                    vertical_flip=vertical_flip, width_shift_range=width_shift_range,\n",
      "                    height_shift_range=height_shift_range)\n",
      "    prepro_fn = functools.partial(_process_img, **prepro_cfg)  \n",
      "\n",
      "    reader_cfg = dict(resize=resize)\n",
      "    reader_fn = functools.partial(_process_pathnames, **reader_cfg)\n",
      "\n",
      "    return _generator(x_train_paths, y_train_paths, reader_fn=reader_fn,\n",
      "                    preproc_fn=prepro_fn, batch_size=batch_size, MAX_IM_QUEUE=MAX_IM_QUEUE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model training "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Arguments:\n",
      "    def __init__(self,\n",
      "                nepochs = 500,\n",
      "                report_step = 5,\n",
      "                batch_size = 1,\n",
      "                validation = 0.2,  \n",
      "                in_shape = (576, 576, 3), \n",
      "                net_loss = 'binary_crossentropy',\n",
      "                net_opt = 'adadelta',\n",
      "                net_lr = 1.,\n",
      "                net_name = 'deconv',\n",
      "                save_dir = '',\n",
      "                database_dir = '',\n",
      "                ftrain = '',\n",
      "                ftest = '',\n",
      "                pretrain='',\n",
      "                gamma=0, \n",
      "                clahe = False,\n",
      "                gray = False,\n",
      "                xyz=False,\n",
      "                hed=False,\n",
      "                rotate_range=0,\n",
      "                save_prefix='', \n",
      "                cout=1): \n",
      "        self.gray = gray\n",
      "        self.xyz = xyz\n",
      "        self.hed = hed\n",
      "        self.gamma = gamma\n",
      "        self.clahe = clahe  \n",
      "        self.rotate_range = rotate_range  \n",
      "        self.cout = cout\n",
      "        self.nepochs = nepochs\n",
      "        self.report_step = report_step\n",
      "        self.batch_size = batch_size\n",
      "        self.validation = validation \n",
      "        self.in_shape = in_shape \n",
      "        self.net_loss = net_loss\n",
      "        self.net_opt = net_opt\n",
      "        self.net_lr = net_lr\n",
      "        self.net_name = net_name\n",
      "        self.save_dir = save_dir\n",
      "        self.database_dir = database_dir\n",
      "        self.ftrain = ftrain \n",
      "        self.ftest = ftest\n",
      "        self.pretrain=pretrain\n",
      "        self.save_prefix=save_prefix "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_and_save(args):\n",
      "    x_train_paths, x_val_paths, y_train_paths, y_val_paths = \\\n",
      "    trainval_splits(args.ftrain, args.database_dir, args.validation)\n",
      " \n",
      "    train_gen = get_gen(x_train_paths, y_train_paths, batch_size=args.batch_size,\n",
      "                        width_shift_range=0.1, height_shift_range=0.1,\n",
      "                        horizontal_flip=True, vertical_flip=True,\n",
      "                        gamma=args.gamma, clahe=args.clahe, gray=args.gray, xyz=args.xyz,hed=args.hed,\n",
      "                        resize=args.in_shape[:2], rotate_range=args.rotate_range) \n",
      "    \n",
      "    val_gen = get_gen(x_val_paths, y_val_paths, batch_size=args.batch_size,\n",
      "                    gamma=args.gamma, clahe=args.clahe, gray=args.gray, xyz=args.xyz,hed=args.hed,\n",
      "                    resize=args.in_shape[:2]) \n",
      "    \n",
      "    pref = ''\n",
      "    if args.gray:\n",
      "        pref += '_gray'\n",
      "    if args.xyz:\n",
      "        pref += '_xyz'\n",
      "    if args.hed:\n",
      "        pref += '_hed'\n",
      "    if args.clahe:\n",
      "        pref += '_clahe'\n",
      "    if args.gamma:\n",
      "        pref += '_gamma'\n",
      "    if 'seg_102' in args.pretrain:\n",
      "        pref += '_p2i'\n",
      "\n",
      "    model = get_net(args.net_name, args.in_shape, cout=args.cout, opt=args.net_opt, \n",
      "                    loss=args.net_loss, lr=args.net_lr)\n",
      "    if os.path.exists(args.pretrain):\n",
      "        model.load_weights(args.pretrain)\n",
      "        print('++++ Pretraining from: ', args.pretrain)\n",
      "    save_model_path  = os.path.join(args.save_dir, args.save_prefix+pref+'_'+args.net_name+'_save_model') \n",
      "    report_file_path = os.path.join(args.save_dir, args.save_prefix+pref+'_'+args.net_name+'_report_file.csv')\n",
      "    mckpt = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path+'.hdf5',\n",
      "                                            monitor='val_loss',\n",
      "                                            save_best_only=True,\n",
      "                                            verbose=1) \n",
      "    \n",
      "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience= 6 * args.report_step, verbose=1) \n",
      "    rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
      "    tb = tf.keras.callbacks.TensorBoard(save_model_path)\n",
      "    csvlog = tf.keras.callbacks.CSVLogger(report_file_path, append=True)  \n",
      "\n",
      "    model.fit_generator(train_gen, shuffle=False, use_multiprocessing=False, workers=3,\n",
      "                        steps_per_epoch= 5 * len(x_train_paths)//args.batch_size + 1,\n",
      "                        epochs=args.nepochs, validation_data=val_gen, \n",
      "                        validation_steps=len(x_val_paths)//args.batch_size,\n",
      "                        callbacks=[mckpt, rlr, tb, csvlog]) \n",
      "\n",
      "    return model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BASE_PATH = os.path.expanduser(\"~/PhD/python/patch2image/\")  \n",
      "DATA_SET = 'DRIVE'\n",
      "DATA_DIR = os.path.expanduser(\"~/PhD/Datasets/\"+DATA_SET+\"/\") \n",
      "\n",
      "train_image_names = BASE_PATH+'datasets/'+DATA_SET+'/train_names.txt'\n",
      "test_image_names  = BASE_PATH+'datasets/'+DATA_SET+'/test_names.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = Arguments(net_name = net_name,\n",
      "                    net_opt = 'adadelta', \n",
      "                    net_lr = 1., \n",
      "                    net_loss ='bce_dice',\n",
      "                    save_prefix = 'seg_101_'+DATA_SET.lower()+'_bce_dice',\n",
      "                    pretrai = '',  # no pretraining\n",
      "                    in_shape = (584, 568, 1),\n",
      "                    save_dir = BASE_PATH+'outputs/'+DATA_SET+'/',\n",
      "                    database_dir = DATA_DIR,\n",
      "                    ftrain = train_image_names,\n",
      "                    ftest = test_image_names,\n",
      "                    gamma = 1.7, \n",
      "                    clahe = True,\n",
      "                    gray = True,) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main(params)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testing(model, args):\n",
      "    x_test_paths, y_test_paths = read_df(args.ftest, args.database_dir)\n",
      "    seg_metrics = []\n",
      "    for x_path, y_path in zip(x_test_paths, y_test_paths):   \n",
      "\n",
      "        im, gt = _process_pathnames(x_path, y_path, resize=args.in_shape[:2]) \n",
      "        im, gt = _process_imgt(im, gt, gamma=args.gamma, clahe=args.clahe, \n",
      "                                gray=args.gray, xyz=args.xyz,hed=args.hed) \n",
      "        pred = model.predict(np.expand_dims(im, 0), steps=1, verbose=1)\n",
      "\n",
      "        seg_metrics.append(misc_metrics(gt, pred))\n",
      "        print('Testing metrics: ', seg_metrics[-1])\n",
      "    print('Final metrics: '+os.path.split(save_model_path)[-1]+'  : ', np.mean(seg_metrics,0))\n",
      "\n",
      "    return model, seg_metrics\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}